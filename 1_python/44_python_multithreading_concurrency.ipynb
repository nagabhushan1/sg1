{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ebc3d9",
   "metadata": {},
   "source": [
    "## Multithreading in Python\n",
    "\n",
    "Multithreading allows multiple threads to execute within the same process.\n",
    "\n",
    "Key points:\n",
    "- Threads share memory\n",
    "- Suitable for I/O-bound tasks\n",
    "- Controlled using the `threading` module\n",
    "- Affected by the Global Interpreter Lock (GIL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc428733",
   "metadata": {},
   "source": [
    "## Task Function\n",
    "\n",
    "This function simulates a blocking operation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9f7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def func(seconds):\n",
    "    print(f\"Sleeping for {seconds} seconds\")\n",
    "    time.sleep(seconds)\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "\n",
    "func(10)\n",
    "func(8)\n",
    "func(5)\n",
    "\n",
    "time2 = time.perf_counter()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b6fc16",
   "metadata": {},
   "source": [
    "Functions execute one after another.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047acd3",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- Each call blocks the next\n",
    "- Total time is cumulative\n",
    "\n",
    "- Simulates an I/O-bound delay\n",
    "- Releases CPU while sleeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32937685",
   "metadata": {},
   "source": [
    "## Multithreading Using threading.Thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378988f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def func(seconds):\n",
    "    print(f\"Sleeping for {seconds} seconds\")\n",
    "    time.sleep(seconds)\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "\n",
    "t1 = threading.Thread(target=func, args=(10,))\n",
    "t2 = threading.Thread(target=func, args=(8,))\n",
    "t3 = threading.Thread(target=func, args=(5,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()\n",
    "t3.join()\n",
    "\n",
    "time2 = time.perf_counter()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec31274e",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- Threads start concurrently\n",
    "- join() ensures completion\n",
    "- Execution time approximates longest task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48510f1b",
   "metadata": {},
   "source": [
    "## ThreadPoolExecutor\n",
    "\n",
    "A high-level API for managing thread pools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09955b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def func(seconds):\n",
    "    print(f\"Sleeping for {seconds} seconds\")\n",
    "    time.sleep(seconds)\n",
    "\n",
    "def poolingDemo():\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future1 = executor.submit(func, 10)\n",
    "        future2 = executor.submit(func, 8)\n",
    "        future3 = executor.submit(func, 5)\n",
    "\n",
    "        future1.result()\n",
    "        future2.result()\n",
    "        future3.result()\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "\n",
    "poolingDemo()\n",
    "time2 = time.perf_counter()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee9418a",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- submit() schedules tasks\n",
    "- result() waits for completion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16e85d6",
   "metadata": {},
   "source": [
    "## ThreadPoolExecutor with map()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39955a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def func(seconds):\n",
    "    print(f\"Sleeping for {seconds} seconds\")\n",
    "    time.sleep(seconds)\n",
    "\n",
    "def poolingDemoMap():\n",
    "    list_timer = [10, 8, 5]\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(func, list_timer)\n",
    "        for r in results:\n",
    "            print(r)\n",
    "\n",
    "time1 = time.perf_counter()\n",
    "poolingDemoMap()\n",
    "time2 = time.perf_counter()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc9b74",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "- map() applies function to iterable\n",
    "- Maintains input order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044339a",
   "metadata": {},
   "source": [
    "What is the GIL?\n",
    "\n",
    "The Global Interpreter Lock (GIL) is a mutex in CPython (the standard Python implementation) that ensures only one thread executes Python bytecode at a time.\n",
    "\n",
    "This design simplifies:\n",
    "- Memory management\n",
    "- Garbage collection\n",
    "- Thread safety for Python objects\n",
    "\n",
    "GIL Limitations\n",
    "- GIL limits multithreading for CPU-bound work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88d358",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Multithreading improves I/O wait utilization\n",
    "- threading.Thread gives manual control\n",
    "- ThreadPoolExecutor simplifies concurrency\n",
    "- Not suitable for CPU-bound workloads\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
